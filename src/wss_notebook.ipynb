{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f6551b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming Client initialized. User ID: 987104e7-e6d3-47f2-82a0-0d3f620aea70\n"
     ]
    }
   ],
   "source": [
    "from scidx_streaming import StreamingClient\n",
    "from ndp_ep import APIClient\n",
    "import os, datetime\n",
    "from dotenv import load_dotenv\n",
    "# ---- Configuration ----\n",
    "load_dotenv(override=True)\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "API_URL = os.getenv(\"API_URL\")\n",
    "SERVER = os.getenv(\"SERVER\")\n",
    "SYNOPTIC_TOKEN = os.getenv(\"SYNOPTIC_TOKEN\")\n",
    "# initializing ndp_ep APIClient\n",
    "client = APIClient(base_url=API_URL, token=TOKEN)\n",
    "streaming = StreamingClient(client)\n",
    "print(f\"Streaming Client initialized. User ID: {streaming.user_id}\")\n",
    "date_time_now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "org_name = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_data = {\n",
    "        \"name\": org_name,\n",
    "        \"title\": org_name,\n",
    "        \"description\": \"Sumaiya test organization for testing purposes\",\n",
    "    }\n",
    "client.register_organization(org_data,server=SERVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2024d079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset registered with ID: e636c4c7-ef55-46d4-8ff1-2f0b44159c75\n",
      "Search returned 6 results. {'name': 'synoptic_push_qcv_aq', 'description': 'Real-time air quality observations from Synoptic Push for station QCV (Copperview).', 'resources': [{'id': '6f5e07c1-9ffe-4357-89b7-b38f3a630684', 'type': 'websocket', 'name': 'synoptic-push-wss-qcv', 'description': 'Synoptic Push WebSocket stream for QCV.', 'config': {'url': 'wss://push.synopticdata.com/feed/e3636084e69244f5bd4d4d2721cec435/?stid=QCV&vars=PM_25_concentration,ozone_concentration,CO_concentration,NO2_concentration', 'token_env': 'SYNOPTIC_TOKEN', 'station_id': 'QCV', 'station_name': 'Copperview', 'latitude': 40.59806, 'longitude': -111.89417, 'elevation_m': 1343.9}}]}\n"
     ]
    }
   ],
   "source": [
    "dataset_metadata = {\n",
    "    \"name\": \"synoptic_push_utah_aq\",\n",
    "    \"title\": \"Synoptic Push Utah Air Quality\",\n",
    "    \"notes\": \"Real-time air quality observations from Synoptic Push (WebSocket).\",\n",
    "    \"owner_org\": org_name,\n",
    "}\n",
    "synoptic_ws_method = {\n",
    "    # \"type\": \"csv\",\n",
    "    \"type\": \"websocket\",\n",
    "    \"name\": \"synoptic-push-wss\",\n",
    "    \"description\": \"Synoptic Push WebSocket stream for selected stations and vars.\",\n",
    "    \"config\": {\n",
    "        \"url\": f\"wss://push.synopticdata.com/feed/{SYNOPTIC_TOKEN}/?stid=QNR&vars=PM_25_concentration,ozone_concentration,CO_concentration,NO2_concentration,air_temp\",\n",
    "        \"token_env\": \"SYNOPTIC_TOKEN\",\n",
    "    }\n",
    "}\n",
    "client.delete_resource_by_name(dataset_metadata['name'],server=SERVER)\n",
    "ds = streaming.register_data_source(\n",
    "        dataset_metadata=dataset_metadata,\n",
    "        methods=[synoptic_ws_method],\n",
    "        server=SERVER,   # or whatever you use\n",
    "    )\n",
    "print(f\"Dataset registered with ID: {ds['id']}\")\n",
    "results = streaming.search_consumption_methods(terms=[\"synoptic\"]) \n",
    "print(f\"Search returned {len(results)} results. {results[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddaf89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream created: data_stream_987104e7-e6d3-47f2-82a0-0d3f620aea70_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[websocket] CONNECTED url=wss://push.synopticdata.com/feed/e3636084e69244f5bd4d4d2721cec435/?stid=QCV&vars=PM_25_concentration,ozone_concentration,CO_concentration,NO2_concentration\n",
      "[websocket] batch -> records=1 msg_types={'auth': 1}\n"
     ]
    }
   ],
   "source": [
    "stream = await streaming.create_kafka_stream(\n",
    "    consumption_method_ids = [results[0][\"resources\"][0][\"id\"]],\n",
    "    filter_semantics=[],\n",
    "    server = SERVER,\n",
    ")\n",
    "\n",
    "topic = stream.data_stream_id\n",
    "print(f\"Stream created: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27412b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming Client initialized. User ID: 987104e7-e6d3-47f2-82a0-0d3f620aea70\n",
      "Consuming from topic: data_stream_987104e7-e6d3-47f2-82a0-0d3f620aea70_1\n",
      "Waiting for data...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "from scidx_streaming import StreamingClient\n",
    "from ndp_ep import APIClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "load_dotenv(override=True)\n",
    "\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "API_URL = os.getenv(\"API_URL\")\n",
    "SERVER = os.getenv(\"SERVER\")\n",
    "\n",
    "client = APIClient(base_url=API_URL, token=TOKEN)\n",
    "streaming = StreamingClient(client)\n",
    "\n",
    "print(f\"Streaming Client initialized. User ID: {streaming.user_id}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Stream (already created)\n",
    "# ----------------------------\n",
    "topic = \"data_stream_987104e7-e6d3-47f2-82a0-0d3f620aea70_1\"\n",
    "print(f\"Consuming from topic: {topic}\")\n",
    "\n",
    "consumer = streaming.consume_kafka_messages(topic)\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def pretty_print_msg(msg: dict):\n",
    "    \"\"\"Nice readable printing for websocket messages\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    pprint(msg, width=120, sort_dicts=False)\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "def normalize_payload_cell(cell):\n",
    "    \"\"\"\n",
    "    payload column may contain:\n",
    "    - dict\n",
    "    - list of dicts / None\n",
    "    \"\"\"\n",
    "    if isinstance(cell, dict):\n",
    "        return [cell]\n",
    "    if isinstance(cell, list):\n",
    "        return [x for x in cell if isinstance(x, dict)]\n",
    "    return []\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main loop\n",
    "# ----------------------------\n",
    "async def main():\n",
    "    print(\"Waiting for data...\\n\")\n",
    "\n",
    "    end_time = datetime.now(timezone.utc) + timedelta(hours=1)\n",
    "\n",
    "    # Track what we have already printed\n",
    "    seen_messages = set()\n",
    "    last_df_signature = None\n",
    "\n",
    "    while datetime.now(timezone.utc) < end_time:\n",
    "        df = consumer.dataframe\n",
    "\n",
    "        if df is not None and not df.empty:\n",
    "            # ---------- Print dataframe only when it updates ----------\n",
    "            signature = (len(df), df[\"timestamp\"].iloc[-1] if \"timestamp\" in df.columns else None)\n",
    "            if signature != last_df_signature:\n",
    "                last_df_signature = signature\n",
    "                print(\"\\nðŸ“Š Updated DataFrame (latest rows):\")\n",
    "                print(df.tail(5).to_string(index=False))\n",
    "\n",
    "            # ---------- Pretty-print raw websocket messages ----------\n",
    "            if \"payload\" in df.columns:\n",
    "                for cell in df[\"payload\"].dropna():\n",
    "                    for msg in normalize_payload_cell(cell):\n",
    "                        # Create a stable hash so we don't print duplicates\n",
    "                        msg_key = json.dumps(msg, sort_keys=True, default=str)\n",
    "\n",
    "                        if msg_key not in seen_messages:\n",
    "                            seen_messages.add(msg_key)\n",
    "                            pretty_print_msg(msg)\n",
    "\n",
    "        await asyncio.sleep(2)\n",
    "\n",
    "    consumer.stop()\n",
    "    print(\"â¹ï¸ No new data after 1 hour. Stopping consumer.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Run\n",
    "# ----------------------------\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bda545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "KEYCLOAK_URL = \"https://idp-test.nationaldataplatform.org/realms/NDP\"\n",
    "CLIENT_ID = \"saleem_test_delete\"  # Should be public (no secret)\n",
    "SCOPE = \"openid profile email\"\n",
    "def get_user_token_device_flow():\n",
    "    device_endpoint = f\"{KEYCLOAK_URL}/protocol/openid-connect/auth/device\"\n",
    "    token_endpoint = f\"{KEYCLOAK_URL}/protocol/openid-connect/token\"\n",
    "    # Step 1: Initiate Device Flow\n",
    "    response = requests.post(device_endpoint, data={\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"scope\": SCOPE\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    print(f\"\\nPlease open this URL in your browser: {data['verification_uri']}\")\n",
    "    print(f\"Enter this code when prompted: {data['user_code']}\\n\")\n",
    "    # Step 2: Poll until approved\n",
    "    while True:\n",
    "        time.sleep(data[\"interval\"])\n",
    "        poll = requests.post(token_endpoint, data={\n",
    "            \"grant_type\": \"urn:ietf:params:oauth:grant-type:device_code\",\n",
    "            \"device_code\": data[\"device_code\"],\n",
    "            \"client_id\": CLIENT_ID\n",
    "        })\n",
    "        if poll.status_code == 200:\n",
    "            print(\"Token received!\")\n",
    "            return poll.json()\n",
    "        elif poll.status_code == 400 and poll.json().get(\"error\") == \"authorization_pending\":\n",
    "            continue\n",
    "        else:\n",
    "            raise Exception(f\"Failed: {poll.status_code} {poll.text}\")\n",
    "# === Get the token ===\n",
    "token_response = get_user_token_device_flow()\n",
    "print(\"Access Token:\", token_response[\"access_token\"])\n",
    "TOKEN = token_response[\"access_token\"]\n",
    "print(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d80e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from websocket import create_connection\n",
    "import json\n",
    "\n",
    "my_token = \"e3636084e69244f5bd4d4d2721cec435\"\n",
    "stream_server = \"wss://push.synopticdata.com/feed/\"\n",
    "# query_arguments = \"units=english&stid=WBB&vars=air_temp,relative_humidity\"\n",
    "query_arguments = \"stid=QNR&vars=PM_25_concentration,ozone_concentration,CO_concentration,NO2_concentration,air_temp\"\n",
    "\n",
    "# then you simply create your connection\n",
    "ws = create_connection(stream_server+my_token+\"/?\"+query_arguments)\n",
    "\n",
    "\n",
    "while True:\n",
    "\tdata = ws.recv()\n",
    "\tjson_data = json.loads(data)\n",
    "\tprint(json_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
